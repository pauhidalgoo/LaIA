<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Assistant Chat</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        .gradient-bg {
            background: linear-gradient(-45deg, #1a1a1a, #2a2a2a, #1a1a1a, #2d2d2d);
            background-size: 400% 400%;
            animation: gradient 15s ease infinite;
        }
        @keyframes gradient {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }
        .glass-effect {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .message-container {
            max-height: calc(100vh - 280px);
        }
        .user-message {
            background: rgba(59, 130, 246, 0.1);
        }
        .assistant-message {
            background: rgba(255, 255, 255, 0.05);
        }
        .system-message {
            background: rgba(34, 197, 94, 0.1);
        }
        
        /* Updated recording button styles */
        .recording-button {
            width: 48px;
            height: 48px;
            border-radius: 50%;
            background: #4a5568;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
        }
        
        .recording-button.recording {
            background: #dc2626;
            animation: pulse 1.5s ease infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(220, 38, 38, 0.7); }
            70% { transform: scale(1.05); box-shadow: 0 0 0 10px rgba(220, 38, 38, 0); }
            100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(220, 38, 38, 0); }
        }
        
        .transcription-status {
            position: absolute;
            top: -25px;
            left: 0;
            right: 0;
            text-align: center;
            font-size: 0.875rem;
            color: #9ca3af;
        }

        .live-transcript {
            position: absolute;
            bottom: -25px;
            left: 0;
            right: 0;
            font-size: 0.875rem;
            color: #9ca3af;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }
    </style>
</head>
<body class="gradient-bg min-h-screen text-gray-100">
    <div class="container mx-auto px-4 py-8 max-w-4xl">
        <div class="sidebar p-4">
            <h2 class="text-xl font-bold mb-4">Documents</h2>
            <div id="documentsList" class="space-y-2">
                <!-- Documents will be inserted here -->
            </div>
        </div>

        <!-- Header -->
        <div class="text-center mb-8">
            <h1 class="text-4xl font-bold mb-2">LaIA</h1>
            <p class="text-gray-400">Ask questions, upload documents, or search the web</p>
        </div>

        <!-- Chat Messages -->
        <div class="glass-effect rounded-lg p-4 mb-4 message-container overflow-y-auto">
            <div id="messages" class="space-y-4">
                <!-- Messages will be inserted here -->
            </div>
        </div>

        <!-- Input Area -->
        <div class="glass-effect rounded-lg p-4">
            <div class="flex items-center gap-4 relative">
                <label class="cursor-pointer">
                    <input type="file" 
                        id="fileInput" 
                        class="hidden" 
                        accept=".pdf,image/*">
                    <i class="fas fa-file-pdf text-blue-400 hover:text-blue-300 text-xl"></i>
                </label>
                
                <div class="flex-1 relative">
                    <div class="transcription-status" id="transcriptionStatus"></div>
                    <input type="text" 
                        id="messageInput" 
                        class="w-full px-4 py-2 rounded-lg bg-white/10 border-0 focus:ring-2 focus:ring-blue-500 outline-none"
                        placeholder="Type your message...">
                    <div class="live-transcript" id="liveTranscript"></div>
                </div>
                
                <button id="recordButton" 
                        class="recording-button"
                        title="Click to start/stop recording">
                    <i class="fas fa-microphone text-white"></i>
                </button>
                
                <button id="sendButton" 
                        class="px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors duration-200 flex items-center gap-2">
                    <i class="fas fa-paper-plane"></i>
                    Send
                </button>
                <button id="clearContextButton" class="px-4 py-2 bg-gray-600 text-white rounded-lg hover:bg-gray-700 transition-colors duration-200">Clear Context</button>
                <button id="ttsToggleButton" class="px-4 py-2 bg-gray-600 text-white rounded-lg hover:bg-gray-700 transition-colors duration-200">TTS On</button>
            </div>
        </div>
    </div>

    <script>
        const sessionId = "{{ session_id }}";
        const messagesContainer = document.getElementById('messages');
        const messageInput = document.getElementById('messageInput');
        const sendButton = document.getElementById('sendButton');
        const fileInput = document.getElementById('fileInput');
        const documentsList = document.getElementById('documentsList');
        const transcriptionStatus = document.getElementById('transcriptionStatus');
        const liveTranscript = document.getElementById('liveTranscript');
        const recordButton = document.getElementById('recordButton');
        
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let ws = null;

        function setupWebSocket() {
            ws = new WebSocket('ws://' + window.location.host + '/ws');
            ws.onmessage = function(event) {
                const data = JSON.parse(event.data);
                if (data.transcription) {
                    liveTranscript.textContent = data.transcription;
                }
            };
            ws.onclose = function() {
                if (isRecording) {
                    setTimeout(setupWebSocket, 1000);
                }
            };
        }

        async function setupMediaRecorder() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const formData = new FormData();
                    formData.append('audio', audioBlob);
                    formData.append('session_id', sessionId);
                    
                    try {
                        const response = await fetch('/transcribe', {
                            method: 'POST',
                            body: formData
                        });
                        
                        const data = await response.json();
                        if (data.transcription) {
                            messageInput.value = (messageInput.value + ' ' + data.transcription).trim();
                            transcriptionStatus.textContent = '';
                            liveTranscript.textContent = '';
                        }
                    } catch (error) {
                        console.error('Transcription error:', error);
                        transcriptionStatus.textContent = 'Transcription failed';
                    }
                    
                    audioChunks = [];
                };

                setupWebSocket();

            } catch (error) {
                console.error('Error accessing microphone:', error);
                recordButton.style.display = 'none';
            }
        }

        function toggleRecording() {
            if (!mediaRecorder) {
                setupMediaRecorder().then(() => startRecording());
                return;
            }
            isRecording ? stopRecording() : startRecording();
        }

        function startRecording() {
            if (mediaRecorder && mediaRecorder.state === 'inactive') {
                isRecording = true;
                audioChunks = [];
                mediaRecorder.start(1000);
                recordButton.classList.add('recording');
                transcriptionStatus.textContent = 'Recording...';
                setupWebSocket();
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                isRecording = false;
                mediaRecorder.stop();
                recordButton.classList.remove('recording');
                transcriptionStatus.textContent = 'Processing...';
                if (ws) {
                    ws.close();
                }
            }
        }

        recordButton.addEventListener('click', toggleRecording);
        
        setupMediaRecorder();
    </script>
</body>
</html>